\documentclass[a4paper,11pt] {article}

\setlength{\hoffset}{-18pt}         
\setlength{\oddsidemargin}{9pt} % Marge gauche sur pages impaires
\setlength{\evensidemargin}{9pt} % Marge gauche sur pages paires
\setlength{\marginparwidth}{54pt} % Largeur de note dans la marge
\setlength{\textwidth}{481pt} % Largeur de la zone de texte (17cm)
\setlength{\voffset}{-18pt} % Bon pour DOS
\setlength{\marginparsep}{7pt} % Séparation de la marge
\setlength{\topmargin}{0pt} % Pas de marge en haut
\setlength{\headheight}{13pt} % Haut de page
\setlength{\headsep}{10pt} % Entre le haut de page et le texte
\setlength{\footskip}{27pt} % Bas de page + séparation
\setlength{\textheight}{708pt} % Hauteur de la zone de texte (25cm)

\usepackage[utf8]{inputenc}
\usepackage[francais]{babel}
\usepackage[T1]{fontenc}
\usepackage{lmodern} % load a font with all the characters
\usepackage{mathtools}
\usepackage{dsfont}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[export]{adjustbox}
\usepackage{listings}
\usepackage{amsthm}
\author{HASSAN Lucas, NGUYEN Le Thanh Dung}
\date{17 janvier 2015}
\usepackage{amsfonts}
\usepackage{stmaryrd}

\begin{document}


\title{Rapport d'étape du projet ECMA (MPRO)}

\maketitle{}

\section{Modélisation du problème sous la forme d'un programme linéaire}

\subsection{Modélisation du problème en ignorant la connexité}

\subsubsection{Modélisation initiale}

Dans un premier temps, on ne s'intéresse pas à la contrainte de connexité du problème.
Celui-ci se modélise alors naturellement de la façon suivante : 

\begin{align*}
\text{maximiser} &\quad \sum_{(i,j)\in M} x_{ij} \\
\text{sous contraintes} &\quad H^p(Z)+H^a(Z) \geq 2 \\
&\quad x_{ij} \in \{0,1\} \text{ pour tout } (i,j) \in M
\end{align*}

où $Z = \{(i,j) \in M \mid x_{ij} = 1\}$, de sorte que la fonction
objectif soit le cardinal de $Z$, et
\begin{align*}
H^p(Z) &= \dfrac{\displaystyle\sum_{(i,j)\in Z} H^p_{ij}C^p_{ij}}{\displaystyle\sum_{(i,j)\in Z} C^p_{ij}} = \dfrac{\displaystyle\sum_{(i,j)\in M} H^p_{ij}C^p_{ij}x_{ij}}{\displaystyle\sum_{(i,j)\in M} C^p_{ij}x_{ij}} \\
H^a(Z) &= \dfrac{\displaystyle\sum_{(i,j)\in Z} H^p_{ij}C^a_{ij}}{\displaystyle\sum_{(i,j)\in Z} C^a_{ij}} = \dfrac{\displaystyle\sum_{(i,j)\in M} H^p_{ij}C^a_{ij}x_{ij}}{\displaystyle\sum_{(i,j)\in M} C^a_{ij}x_{ij}}
\end{align*}

Cette formulation contient des variables binaires (0--1), une fonction
objectif linéaire, et une contrainte \textit{fractionnaire}.

\subsubsection{Linéarisation de la contrainte fractionnaire}

On veut se ramener à un programme linéaire en nombres entiers. 

Introduisons les variables réelles $p$ et $a$ telles que :
\[ p = \sum_{(i,j)\in M} C^p_{ij}x_{ij} \qquad a = \sum_{(i,j)\in M} C^a_{ij}x_{ij} \]

On a alors $p \geq 0$, $a \geq 0$, et dès que $(x_{ij})$ n'est pas
identiquement nul -- ce qui sera le cas de la solution optimale, étant
donnée la fonction qu'on cherche à maximiser -- on a $p > 0$ et
$a > 0$. On peut donc multiplier la contrainte par $pa$ pour obtenir
la formulation équivalente
\[ \sum_{(i,j)\in M} H^p_{ij}C^p_{ij}x_{ij}a + \sum_{(i,j)\in M} H^a_{ij}C^a_{ij}x_{ij}p
\geq 2pa = \sum_{(k,l)\in M} 2C^a_{kl}x_{kl}p
\]

On a désormais un programme \textit{quadratique} en variables 0--1,
reste à le linéariser. Définissons, pour tout $(i,j)\in M$,
$a_{ij}=ax_{ij}$ et $p_{ij}=px_{ij}$. On sait que les 4 inégalités
\textit{linéaires} :
\begin{align*}
a_{ij} &\leq a_{\mathrm{max}}x_{ij}\\
a_{ij} &\leq a\\
a_{ij} &\geq (x_{ij}-1)a_{\mathrm{max}}+a\\
a_{ij} &\geq 0
\end{align*}
sont équivalentes à $a_{ij} = ax_{ij}$ lorsque $x_{ij} \in \{0,1\}$ et
$a \in [0,a_{\textrm{max}}]$. On peut prendre la constante
$a_{\mathrm{max}} = \sum_{(i,j)\in M} C^a_{ij}$ comme majorant trivial
de $a$. Il en va de même pour l'égalité $p_{ij}=px_{ij}$.

Ainsi, le problème linéarisé est : 
\begin{align*}
\max &\quad \sum_{(i,j)\in M} x_{ij}\\
\text{s.c.} &\quad  \sum_{(i,j)\in M} H^p_{ij}C^p_{ij}a_{ij} + \sum_{(i,j)\in M} H^a_{ij}C^a_{ij}p_{ij} \geq \sum_{(i,j)\in M} 2C^a_{ij}p_{ij}\\
&\quad  \begin{array}{lll}
    \forall{(i,j)} \in M&a_{ij}\leq a_{\mathrm{max}}x_{ij}&p_{ij}\leq p_{max}x_{ij}\\
    \forall{(i,j)} \in M&a_{ij}\leq a&p_{ij}\leq p\\
    \forall{(i,j)} \in M&a_{ij}\geq (x_{ij}-1)a_{\mathrm{max}}+a&p_{ij}\geq (x_{ij}-1)p_{max}+p\\
                        &a = \displaystyle\sum_{(i,j)\in M} C^a_{ij}x_{ij}&p = \displaystyle\sum_{(i,j)\in M} C^p_{ij}x_{ij}\\
    \forall{(i,j)} \in M & x_{ij} \in \{0,1\},\; a_{ij}, p_{ij} \in \mathbb{R}_+ \\
	\end{array}
\end{align*}
les variables de décision étant donc les $x_{ij}$, $a_{ij}$ et $p_{ij}$.

\subsection{Prise en compte de la contrainte de connexité}

Une commune peut être représentée par un graphe non orienté tel que
chaque maille $(i,j)$ soit un nœud du graphe, les nœuds étant reliés
par des arêtes si les mailles correspondantes sont adjacentes dans
$M$. La contiguïté des mailles de $Z$ est alors équivalente à la
connexité du sous-graphe induit par le sous-ensemble de sommets $Z$.

Un graphe non vide est connexe si et seulement s'il existe un sommet
relié à tous les autres. Considérons une maille \og{}centrale\fg{}
$(i_0,j_0) \in Z$ qu'on distinguera des autres. À partir de celle-ci,
affectons aux autres une \textit{distance} de sorte que si
$(i,j) \in Z$ est à distance $k$ (sous-entendu : du centre), alors il
existe un chemin entre $(i_0, j_0)$ et $(i,j)$ passant par des nœuds
de distances successives $0, 1, \ldots, k$. Un tel chemin étant simple
il ne peut pas être de longueur plus grande que le nombre de nœuds du
graphe ; par conséquent, $k \leq |M| - 1$. (Attention, la distance
n'est pas forcément la longueur du \textit{plus court} chemin !)

Il est alors clair que les mailles auxquelles on peut attribuer une
distance sont alors celles accessibles à partir de $(i_0, j_0)$,
c'est-à-dire la composante connexe du nœud central. La connexité se
caractérise ainsi par l'existence d'une distance pour toutes les
mailles de $Z$, pour un certain choix de centre.

%   On dira qu'un nœud $(i,j)$ est à distance
% $k$ d'un nœud $(m,n)$ si il existe une chaîne de taille $k$ allant de
% $(i,j)$ vers $(m,n)$.

Introduisons donc les variables de décision $S_{i,j,k}$, pour
$(i,j,k) \in M \times \llbracket 0 \,;\, |M|-1 \rrbracket$ valant :
\begin{itemize}
\item $1$ si le nœud $(i,j)$ est dans $Z$ et se trouve à distance $k$ du nœud central,
\item $0$ sinon.
\end{itemize}
Ce que l'on spécifie par les contraintes suivantes :
\begin{align*}
  & \sum_{(i,j)\in M} S_{i,j,0} = 1\\
  \forall{(i,j)}\in M, &\; \sum_{k = 0}^{|M|} S_{ijk} = x_{ij}\\
  \forall{(i,j,k)}\in M \times \llbracket 1 \,;\, |M|-1
  \rrbracket,&\; S_{i,j,k} \leq S_{i-1,j,k-1} + S_{i+1,j,k-1} + S_{i,j-1,k-1} + S_{i,j+1,k-1}
\end{align*}
(Afin que la dernière inégalité ait un sens pour les mailles au bord
de la grille, on considérera que lorsque $(i,j) \not\in M$, $S_{ijk}$
dénote non pas l'une des variables de décision mais la constante $0$.)

% (Les effets de bords pour la dernière contrainte ne sont pas spécifiés pour simplifier les notations)

\begin{itemize}
\item La première contrainte assure de choisir un et un seul nœud central. En effet, on ne spécifie pas la maille centrale à l'avance, elle sera caractérisée par $S_{i_0, j_0, 0} = 1$.
\item La seconde contrainte joue deux rôles :
  \begin{itemize}
  \item dans le cas où $x_{ij}=0$ elle s'assure de n'attribuer de
    distance que pour les mailles de $Z$, ce qui garantit qu'on ne
    relie pas deux sommets par un chemin qui intersecte
    $M \setminus Z$ ;
  \item dans le cas où $x_{ij}=1$, elle force la maille à se voir
    attribuer exactement une distance, ce qui ne pourra pas être le
    cas si elle n'est pas accessible. Cette contrainte sera donc
    violée si $Z$ n'est pas connexe.
  \end{itemize}
\item La dernière contrainte assure que $(i,j)$ ne peut être à distance $k$ que si au moins l'un de ses voisins est à distance $k-1$. Ainsi, ce voisin sera un prédécesseur possible de $(i,j)$ dans un chemin de longueur $k$ partant de la maille centrale.
\end{itemize}

% Le problème global s'écrit donc : 

% \begin{equation}
% \left\{
% \begin{array}{l}
% \max \sum_{(i,j)\in M} x_{ij}\\
% \sum_{(i,j)\in M} H^p_{ij}C^p_{ij}a_{ij} + \sum_{(i,j)\in M} H^a_{ij}C^a_{ij}p_{ij} \geq 2(\sum_{(i,j)\in M} C^a_{ij}p_{ij})\\
% 	\begin{array}{lll}
% 		\forall{(i,j)} \in M&a_{ij}\leq a_{\mathrm{max}}x_{ij}&p_{ij}\leq p_{max}x_{ij}\\
% 		\forall{(i,j)} \in M&a_{ij}\leq a&p_{ij}\leq p\\
% 		\forall{(i,j)} \in M&a_{ij}\geq (x_{ij}-1)a_{\mathrm{max}}+a&p_{ij}\geq (x_{ij}-1)p_{max}+p\\
% 		\forall{(i,j)} \in M&a_{ij} \geq 0&p_{ij} \geq 0\\
% 		&a = (\sum_{(i,j)\in M} C^a_{ij}x_{ij})&p = (\sum_{(i,j)\in M} C^p_{ij}x_{ij})\\
% 		&p > 0&a > 0\\
% 		\forall{k} \in N&\sum_{(k)\in M} S_{ijk} = x_{ij}&\sum_{(i,j)\in M} S_{i,j,0} = 1\\
% 		\forall{(i,j,k)} \in M \times N&S_{i,j,k}\leq S_{i-1,j,k-1} + S_{i+1,j,k-1} + S_{i,j-1,k-1} + S_{i,j+1,k-1}
% 	\end{array}
	
% \end{array}
% \right.
% \end{equation}

\subsubsection{Remarques}

Les résultats seront présentés dans le rapport final, mais on peut
déjà constater que la contrainte de connexité engendre un nombre très
important de variables de décision (de l'ordre de $|M|^2$). Même sur
des instances de taille très raisonnable ($10 \times 10$), on génère
10000 variables. Une première question sera donc de se demander si on
peut limiter le nombre de variables à ajouter pour définir les
contraintes de connexité.

De plus, on peut remarquer que dans la solution finale, les valeurs
des $S_{ijk}$ sont presque toutes nulles. En effet, si les $x_{ij}$
définissent un ensemble de mailles $Z$, on aura seulement
$|Z| \leq |M|$ valeurs non nulles de $S_{ijk}$ parmi $|M|^2$ variables
au total ! On a donc fortement intérêt à brancher de préférence
$S_{ijk}$ vers sa valeur inférieure (nulle ici) dans le branch and cut.

Les résultats et d'autres améliorations seront présentés dans le
rapport final.
\end{document}